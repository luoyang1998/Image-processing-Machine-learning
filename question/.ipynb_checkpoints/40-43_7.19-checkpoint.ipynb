{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40-JPEG 压缩——第四步：YCbCr+离散余弦变换+量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将图像转为 YCbCr 色彩空间之后，进行 离散余弦变换再对 Y 用 Q1 量化矩阵量化，Cb 和 Cr 用 Q2 量化矩阵量化。最后通过离散余弦逆变换对图像复原。还需比较图像的容量。算法如下：\n",
    "\n",
    "1. 将图像从RGB色彩空间变换到YCbCr色彩空间；\n",
    "2. 对YCbCr做DCT；\n",
    "3. DCT之后做量化；\n",
    "4. 量化之后应用IDCT；\n",
    "5. IDCT之后从YCbCr色彩空间变换到RGB色彩空间。\n",
    "\n",
    "这是实际生活中使用的减少 JPEG 数据量的方法，Q1 和 Q2 根据 JPEG 规范由以下等式定义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q1 = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "               (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "               (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "               (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "               (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "               (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "               (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "               (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)$$\n",
    "\n",
    "$$Q2 = np.array(((17, 18, 24, 47, 99, 99, 99, 99),\n",
    "               (18, 21, 26, 66, 99, 99, 99, 99),\n",
    "               (24, 26, 56, 99, 99, 99, 99, 99),\n",
    "               (47, 66, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99)), dtype=np.float32)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT参数\n",
    "T = 8\n",
    "K = 8\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR -> YCbCr\n",
    "def BGR2YCbCr(img):\n",
    "    \n",
    "    H, W, C = img.shape\n",
    "\n",
    "    ycbcr = np.zeros([H, W, 3], dtype=np.float32)\n",
    "\n",
    "    ycbcr[..., 0] = 0.2990 * img[..., 2] + 0.5870 * img[..., 1] + 0.1140 * img[..., 0]\n",
    "    ycbcr[..., 1] = -0.1687 * img[..., 2] - 0.3313 * img[..., 1] + 0.5 * img[..., 0] + 128.\n",
    "    ycbcr[..., 2] = 0.5 * img[..., 2] - 0.4187 * img[..., 1] - 0.0813 * img[..., 0] + 128.\n",
    "\n",
    "    return ycbcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YCbCr -> BGR\n",
    "def YCbCr2BGR(ycbcr):\n",
    "    \n",
    "    H, W, C = ycbcr.shape\n",
    "\n",
    "    bgr = np.zeros([H, W, channel], dtype=np.float32)\n",
    "\n",
    "    bgr[..., 2] = ycbcr[..., 0] + (ycbcr[..., 2] - 128.) * 1.4020\n",
    "    bgr[..., 1] = ycbcr[..., 0] - (ycbcr[..., 1] - 128.) * 0.3441 - (ycbcr[..., 2] - 128.) * 0.7139\n",
    "    bgr[..., 0] = ycbcr[..., 0] + (ycbcr[..., 1] - 128.) * 1.7718\n",
    "\n",
    "    bgr = np.clip(bgr, 0, 255)\n",
    "    bgr = bgr.astype(np.uint8)\n",
    "\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT 权重\n",
    "def DCT_w(x, y, u, v):\n",
    "    \n",
    "    cu = 1.\n",
    "    cv = 1.\n",
    "    \n",
    "    if u == 0:\n",
    "        cu /= np.sqrt(2)\n",
    "        \n",
    "    if v == 0:\n",
    "        cv /= np.sqrt(2)\n",
    "        \n",
    "    theta = np.pi / (2 * T)\n",
    "    \n",
    "    return (( 2 * cu * cv / T) * np.cos((2*x+1)*u*theta) * np.cos((2*y+1)*v*theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT\n",
    "def dct(img):\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    F = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "    for c in range(channel):\n",
    "        for yi in range(0, H, T):\n",
    "            for xi in range(0, W, T):\n",
    "                for v in range(T):\n",
    "                    for u in range(T):\n",
    "                        for y in range(T):\n",
    "                            for x in range(T):\n",
    "                                F[v+yi, u+xi, c] += img[y+yi, x+xi, c] * DCT_w(x,y,u,v)\n",
    "                                \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDCT\n",
    "def idct(F):\n",
    "    \n",
    "    H, W, _ = F.shape\n",
    "\n",
    "    out = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "    for c in range(channel):\n",
    "        for yi in range(0, H, T):\n",
    "            for xi in range(0, W, T):\n",
    "                for y in range(T):\n",
    "                    for x in range(T):\n",
    "                        for v in range(K):\n",
    "                            for u in range(K):\n",
    "                                out[y+yi, x+xi, c] += F[v+yi, u+xi, c] * DCT_w(x,y,u,v)\n",
    "\n",
    "    out = np.clip(out, 0, 255)\n",
    "    out = np.round(out).astype(np.uint8)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量化\n",
    "def quantization(F):\n",
    "    \n",
    "    H, W, _ = F.shape\n",
    "\n",
    "    Q = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "                (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "                (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "                (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "                (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "                (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "                (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "                (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)\n",
    "\n",
    "    for ys in range(0, H, T):\n",
    "        for xs in range(0, W, T):\n",
    "            for c in range(channel):\n",
    "                F[ys: ys + T, xs: xs + T, c] =  np.round(F[ys: ys + T, xs: xs + T, c] / Q) * Q\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG without Hufman coding\n",
    "\n",
    "def JPEG(img):\n",
    "    \n",
    "    # BGR -> YCbCr\n",
    "    ycbcr = BGR2YCbCr(img)\n",
    "\n",
    "    # DCT\n",
    "    F = dct(ycbcr)\n",
    "\n",
    "    # quantization\n",
    "    F = quantization(F)\n",
    "\n",
    "    # IDCT\n",
    "    ycbcr = idct(F)\n",
    "\n",
    "    # YCbCr -> BGR\n",
    "    out = YCbCr2BGR(ycbcr)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def MSE(img1, img2):\n",
    "    H, W, _ = img1.shape\n",
    "    mse = np.sum((img1 - img2) ** 2) / (H * W * channel)\n",
    "    return mse\n",
    "\n",
    "# PSNR\n",
    "def PSNR(mse, vmax=255):\n",
    "    return 10 * np.log10(vmax * vmax / mse)\n",
    "\n",
    "# bitrate\n",
    "def BITRATE():\n",
    "    return 1. * T * K * K / T / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../picture/chans.png\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG\n",
    "out = JPEG(img)\n",
    "\n",
    "# MSE\n",
    "mse = MSE(img, out)\n",
    "\n",
    "# PSNR\n",
    "psnr = PSNR(mse)\n",
    "\n",
    "# bitrate\n",
    "bitrate = BITRATE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 35.82757568359375\n",
      "PSNR: 32.58862938770976\n",
      "bitrate: 8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\", mse)\n",
    "print(\"PSNR:\", psnr)\n",
    "print(\"bitrate:\", bitrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result40_JPEG.jpg', out)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 41-Canny边缘检测：第一步——边缘强度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像边缘检测的方法：\n",
    "\n",
    "1. 使用高斯滤波；\n",
    "2. 在$x$方向和$y$方向上使用Sobel滤波器，在此之上求出边缘的强度和边缘的梯度；\n",
    "3. 对梯度幅值进行非极大值抑制（Non-maximum suppression）来使边缘变得更细；\n",
    "4. 使用滞后阈值来对阈值进行处理。\n",
    "\n",
    "完成第一步和第二步，按照以下步骤进行处理：\n",
    "\n",
    "1. 将图像进行灰度化处理；\n",
    "\n",
    "2. 将图像进行高斯滤波（$5\\times5$，$s=1.4$）；\n",
    "\n",
    "3. 在$x$方向和$y$方向上使用Sobel滤波器，在此之上求出边缘梯度$f_x$和$f_y$。边缘梯度可以按照下式求得： $$ \\text{edge}=\\sqrt{{f_x}^2+{f_y}^2}\\ $$ $$ \\text{tan}=\\arctan(\\frac{f_y}{f_x}) $$\n",
    "\n",
    "4. 使用下面的公式将梯度方向量化： $$ \\text{angle}=\\begin{cases} 0 & (\\text{if}\\quad -0.4142 < \\tan \\leq 0.4142)\\ 45 & (\\text{if}\\quad 0.4142 < \\tan < 2.4142)\\ 90 &(\\text{if}\\quad |\\tan| \\geq 2.4142)\\ 135 &(\\text{if}\\quad -2.4142 < \\tan \\leq -0.4142) \\end{cases} $$\n",
    "\n",
    "使用numpy.pad()来设置滤波器的padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread(\"../picture/imori.jpg\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 灰度化\n",
    "def BGR2GRAY(img):\n",
    "    b = img[:, :, 0].copy()\n",
    "    g = img[:, :, 1].copy()\n",
    "    r = img[:, :, 2].copy()\n",
    "    \n",
    "    out = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "    out = out.astype(np.uint8)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian\n",
    "def Gaussian_filter(img, K_size, sigma):\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        H, W, C = img.shape\n",
    "        gray = False\n",
    "    else:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        H, W, C = img.shape\n",
    "        gray = True\n",
    "        \n",
    "    # Zero padding\n",
    "    pad = K_size // 2\n",
    "    out = np.zeros([H + pad * 2, W + pad * 2, C], dtype=np.float)\n",
    "    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "    # prepare Kernel\n",
    "    K = np.zeros((K_size, K_size), dtype=np.float)\n",
    "    for x in range(-pad, -pad + K_size):\n",
    "        for y in range(-pad, -pad + K_size):\n",
    "            K[y + pad, x + pad] = np.exp( - (x ** 2 + y ** 2) / (2 * (sigma ** 2)))\n",
    "    K /= (2 * np.pi * sigma * sigma)\n",
    "    K /= K.sum()\n",
    "\n",
    "    tmp = out.copy()\n",
    "\n",
    "    # filtering\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            for c in range(C):\n",
    "                out[pad + y, pad + x, c] = np.sum(K * tmp[y : y + K_size, x : x + K_size, c])\n",
    "                \n",
    "    out = np.clip(out, 0, 255)\n",
    "    out = out[pad : pad + H, pad : pad + W]\n",
    "\n",
    "    if gray:\n",
    "        out = out[..., 0]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Sobel\n",
    "def Sobel_filter(img, K_size):\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        H, W, C = img.shape\n",
    "    else:\n",
    "        H, W = img.shape\n",
    "\n",
    "    # Zero padding\n",
    "    pad = K_size // 2\n",
    "    out = np.zeros((H + pad * 2, W + pad * 2), dtype=np.float)\n",
    "    out[pad : pad + H, pad : pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "    tmp = out.copy()\n",
    "    out_v = out.copy()\n",
    "    out_h = out.copy()\n",
    "    \n",
    "    # Sobel vertical\n",
    "    Kv = [[1., 2., 1.],[0., 0., 0.], [-1., -2., -1.]]\n",
    "    # Sobel horizontal\n",
    "    Kh = [[1., 0., -1.],[2., 0., -2.],[1., 0., -1.]]\n",
    "\n",
    "    # filtering\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            out_v[pad + y, pad + x] = np.sum(Kv * tmp[y : y + K_size, x : x + K_size])\n",
    "            out_h[pad + y, pad + x] = np.sum(Kh * tmp[y : y + K_size, x : x + K_size])\n",
    "                \n",
    "    out_v = np.clip(out_v, 0, 255)\n",
    "    out_h = np.clip(out_h, 0, 255)\n",
    "    \n",
    "    out_v = out_v[pad : pad + H, pad : pad + W].astype(np.uint8)\n",
    "    out_h = out_h[pad : pad + H, pad : pad + W].astype(np.uint8)\n",
    "\n",
    "    return out_v, out_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge strength, angle\n",
    "def get_edge_angle(fx, fy):\n",
    "    \n",
    "    edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "    fx = np.maximum(fx, 1e-5)\n",
    "    \n",
    "    angle = np.arctan(fy / fx)\n",
    "    \n",
    "    return edge, angle\n",
    "\n",
    "def angle_quantization(angle):\n",
    "    \n",
    "    angle = angle / np.pi * 180\n",
    "    \n",
    "    angle[angle < -22.5] = 180 + angle[angle < -22.5]\n",
    "    _angle = np.zeros_like(angle, dtype=np.uint8)\n",
    "    _angle[np.where(angle <= 22.5)] = 0\n",
    "    _angle[np.where((angle > 22.5) & (angle <= 67.5))] = 45\n",
    "    _angle[np.where((angle > 67.5) & (angle <= 112.5))] = 90\n",
    "    _angle[np.where((angle > 112.5) & (angle <= 157.5))] = 135\n",
    "    \n",
    "    return _angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Canny_step1(img):\n",
    "    \n",
    "    # grayscale\n",
    "    gray = BGR2GRAY(img)\n",
    "\n",
    "    # gaussian filtering\n",
    "    gaussian = Gaussian_filter(gray, K_size=5, sigma=1.4)\n",
    "\n",
    "    # sobel filtering\n",
    "    fy, fx = Sobel_filter(gaussian, K_size=3)\n",
    "\n",
    "    # get edge strength, angle\n",
    "    edge, angle = get_edge_angle(fx, fy)\n",
    "\n",
    "    # angle quantization\n",
    "    angle = angle_quantization(angle)\n",
    "\n",
    "    return edge, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny (step1)\n",
    "edge, angle = Canny_step1(img)\n",
    "\n",
    "edge = edge.astype(np.uint8)\n",
    "angle = angle.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result41_edge.jpg', edge)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", edge)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result41_angle.jpg', angle)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", angle)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 42-Canny边缘检测：第二步——边缘细化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成Canny边缘检测的第三步。\n",
    "\n",
    "从在第四十一问中求出的边缘梯度进行非极大值抑制，来对边缘进行细化。\n",
    "\n",
    "非极大值抑制是对除去非极大值以外的值的操作的总称（这个术语在其它的任务中也经常出现）。\n",
    "\n",
    "比较所关注的地方梯度的法线方向邻接的三个像素点的梯度幅值，如果该点的梯度值不比其它两个像素大，那么这个地方的值设置为0。\n",
    "\n",
    "在注意梯度幅值$\\text{edge}(x,y)$的时候，可以根据下式由梯度方向$\\text{angle}(x,y)$来变换$\\text{edge}(x,y)$： \n",
    "\n",
    "$\\text{angle}(x,y) = 0$\n",
    "如果在$\\text{edge}(x,y)$、$\\text{edge}(x-1,y)$、$\\text{edge}(x+1,y)$中$\\text{edge}(x,y)$不是最大的，那么$\\text{edge}(x,y)=0$；\n",
    "\n",
    "$\\text{angle}(x,y) = 45$\n",
    "如果在$\\text{edge}(x,y)$、$\\text{edge}(x-1,y)$、$\\text{edge}(x+1,y)$中$\\text{edge}(x,y)$不是最大的，那么$\\text{edge}(x,y)=0$；\n",
    "\n",
    "$\\text{angle}(x,y) = 90$\n",
    "如果在$\\text{edge}(x,y)$、$\\text{edge}(x-1,y)$、$\\text{edge}(x+1,y)$中$\\text{edge}(x,y)$不是最大的，那么$\\text{edge}(x,y)=0$；\n",
    "\n",
    "$\\text{angle}(x,y) = 135$\n",
    "如果在$\\text{edge}(x,y)$、$\\text{edge}(x-1,y)$、$\\text{edge}(x+1,y)$中$\\text{edge}(x,y)$不是最大的，那么$\\text{edge}(x,y)=0$；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非极大值抑制\n",
    "def non_maximum_suppression(angle, edge):\n",
    "    \n",
    "    H, W = angle.shape\n",
    "    _edge = edge.copy()\n",
    "    \n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            if angle[y, x] == 0:\n",
    "                dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "            elif angle[y, x] == 45:\n",
    "                dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "            elif angle[y, x] == 90:\n",
    "                dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "            elif angle[y, x] == 135:\n",
    "                dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "            \n",
    "            if x == 0:\n",
    "                dx1 = max(dx1, 0)\n",
    "                dx2 = max(dx2, 0)\n",
    "            if x == W-1:\n",
    "                dx1 = min(dx1, 0)\n",
    "                dx2 = min(dx2, 0)\n",
    "            if y == 0:\n",
    "                dy1 = max(dy1, 0)\n",
    "                dy2 = max(dy2, 0)\n",
    "            if y == H-1:\n",
    "                dy1 = min(dy1, 0)\n",
    "                dy2 = min(dy2, 0)\n",
    "                \n",
    "            if max(max(edge[y, x], edge[y + dy1, x + dx1]), edge[y + dy2, x + dx2]) != edge[y, x]:\n",
    "                _edge[y, x] = 0\n",
    "    \n",
    "    return _edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Canny_step3(img):\n",
    "\n",
    "    # grayscale\n",
    "    gray = BGR2GRAY(img)\n",
    "\n",
    "    # gaussian filtering\n",
    "    gaussian = Gaussian_filter(gray, K_size=5, sigma=1.4)\n",
    "\n",
    "    # sobel filtering\n",
    "    fy, fx = Sobel_filter(gaussian, K_size=3)\n",
    "\n",
    "    # get edge strength, angle\n",
    "    edge, angle = get_edge_angle(fx, fy)\n",
    "\n",
    "    # angle quantization\n",
    "    angle = angle_quantization(angle)\n",
    "    \n",
    "    # non maximum suppression\n",
    "    edge = non_maximum_suppression(angle, edge)\n",
    "\n",
    "    return edge, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny (step3)\n",
    "edge, angle = Canny_step3(img)\n",
    "\n",
    "edge = edge.astype(np.uint8)\n",
    "angle = angle.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result42_edge.jpg', edge)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", edge)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result42_angle.jpg', angle)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", angle)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 43-Canny 边缘检测：第三步——滞后阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行 Canny 边缘检测的最后一步。\n",
    "\n",
    "将通过设置高阈值（HT：high threshold）和低阈值（LT：low threshold）来将梯度幅值二值化。\n",
    "\n",
    "如果梯度幅值$edge(x,y)$大于高阈值的话，令$edge(x,y)=255$；\n",
    "\n",
    "如果梯度幅值$edge(x,y)$小于低阈值的话，令$edge(x,y)=0$；\n",
    "\n",
    "如果梯度幅值$edge(x,y)$介于高阈值和低阈值之间并且周围8邻域内有比高阈值高的像素点存在，令$edge(x,y)=255$；\n",
    "\n",
    "使高阈值为100，低阈值为20。阈值的大小需要边看结果边调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 阈值\n",
    "def hysterisis(edge, HT, LT):\n",
    "    \n",
    "    H, W = edge.shape\n",
    "    \n",
    "    edge[edge >= HT] = 255\n",
    "    edge[edge <= LT] = 0\n",
    "    \n",
    "    _edge = np.zeros((H + 2, W + 2), dtype=np.float32)\n",
    "    _edge[1 : H + 1, 1 : W + 1] = edge\n",
    "    \n",
    "    # 8 - Nearest neighbor\n",
    "    nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "    \n",
    "    for y in range(1, H+2):\n",
    "        for x in range(1, W+2):\n",
    "            if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "                continue\n",
    "            if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "                _edge[y, x] = 255\n",
    "            else:\n",
    "                _edge[y, x] = 0\n",
    "                \n",
    "    edge = _edge[1:H+1, 1:W+1]\n",
    "    \n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Canny(img):\n",
    "    \n",
    "    # grayscale\n",
    "    gray = BGR2GRAY(img)\n",
    "\n",
    "    # gaussian filtering\n",
    "    gaussian = Gaussian_filter(gray, K_size=5, sigma=1.4)\n",
    "\n",
    "    # sobel filtering\n",
    "    fy, fx = Sobel_filter(gaussian, K_size=3, sigma=1.3)\n",
    "\n",
    "    # get edge strength, angle\n",
    "    edge, angle = get_edge_angle(fx, fy)\n",
    "\n",
    "    # angle quantization\n",
    "    angle = angle_quantization(angle)\n",
    "    \n",
    "    # non maximum suppression\n",
    "    edge = non_maximum_suppression(angle, edge)\n",
    "    \n",
    "    # hysterisis threshold\n",
    "    out = hysterisis(edge, 50, 20)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny (step4)\n",
    "edge3 = Canny(img2)\n",
    "\n",
    "edge3 = edge3.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../picture/chan_result43_edge.jpg', edge3)\n",
    "cv2.namedWindow(\"result\", 0);\n",
    "cv2.resizeWindow(\"result\", (600, 600));\n",
    "cv2.imshow(\"result\", edge3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
